#Definir directorio de trabajo
getwd()
setwd("/Users/nairachiclana/Documents/Github/R_for_BI-Season2/") #Cambiar por el personal de cada uno
#Comprobar que se ha configurado correctamente
getwd()
# -----------Leer archivo csv con read.table() ---------------------------------------------
df_main_table<-read.table("data/Rossmann/main.csv") # sep= " " por defecto
df_main_table<-read.table("data/Rossmann/main.csv", sep=",") #header=FALSE por defecto
head(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv", header=TRUE, sep=",")
head(df_main_table)
#Otras utilidades de la función read.table()
?read.table()
#leer solo las n primeras lineas
dim(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv", header=TRUE, sep=",", nrows=1000)
dim(df_main_table)
#empezar a leer 1000 lineas después de las 300 primeras lineas
head(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv",  sep=",", nrows=1000, skip=300)
head(df_main_table)
#crear vector de nombres
name_of_columns=c("Id", "Store", "DayOfWeek", "Date", "Open", "Promo", "StateHoliday", "SchoolHoliday")
df_main_table<-read.table("data/Rossmann/main.csv",  sep=",", nrows=1000, skip=300, col.names=name_of_columns)
head(df_main_table)
# -----------Leer archivo csv con read.csv()---------------------------------------------
df_main_csv<-read.csv("data/Rossmann/main.csv") #header=TRUE and sep="," por defecto
head(df_main_csv)
?read.csv
#install.packages("readxl")
library(readxl)
library(xlsx)
df_store_excel<-read_excel("data/Rossmann/store.xlsm")
head(df_store_excel)
class(df_store_excel)
df_store_excel2<-read.xlsx(xlsxFile="data/Rossmann/store.xlsm")
head(df_store_excel2)
?read.xlsx
#Leemos hoja distinta a la princial
read.xlsx("data/Rossmann/store.xlsm", sheet=2) #por defecto salta lineas vacías al principio del archivo
#SOLUCIÓN
read.xlsx("data/Rossmann/store.xlsm", sheet=2, colNames=FALSE, na.strings=c("-", " "))
read.xlsx("data/Rossmann/store.xlsm", sheet=2, colNames=TRUE, check.names=TRUE)
#Con la función dim() podemos definir o ver la dimensión de un objeto. En un df vemos el número de filas y columnas.
dim(df_main_csv)
dim(df_store_excel)
#El conjunto "main" es algo grande, lo reduciremos a 500k observaciones para tratarlo con más velocidad.
#Nos quedaremos con 50k filas de forma aleatoria para intentar que los datos se sesguen lo mínimo posible.
#La función sample_n selecciona aleatoriamente las  filas indicadas del conjunto
library(dplyr)
df_main_reduced<-sample_n(df_main_csv, 500000)
dim(df_main_reduced)
#Para elegir el número de filas de forma dinámica, sabiendo que queremos más o menos la mitad,
#podemos crear una variable con el valor de la mitad del número de filas, obtenido con la función nrow()
mitad_filas<-nrow(df_main_csv)/2
df_main_reduced<-sample_n(df_main_csv, mitad_filas)
dim(df_main_reduced)
#Tipos de datos del conjunto df_main
str(df_main_reduced)
#con la función unique() vemos los valores distintos que contiene una variable
unique(df_main_reduced$DayOfWeek)
#día de la semana tiene solo 7 valores distintos, por lo que la convertiremos de numérica a factor con la función as.factor()
df_main_reduced$DayOfWeek<-as.factor(df_main_reduced$DayOfWeek)
#comprobamos que se ha transformado correctamente con la función class()
class(df_main_reduced$DayOfWeek)
#Realizamos el mismo proceso para la variable Promo
unique(df_main_reduced$Promo)
df_main_reduced$Promo<-as.factor(df_main_reduced$Promo)
class(df_main_reduced$Promo)
#Y para la variable SchoolHoliday
unique(df_main_reduced$SchoolHoliday)
df_main_reduced$SchoolHoliday<-as.factor(df_main_reduced$SchoolHoliday)
class(df_main_reduced$SchoolHoliday)
#La fecha, debería estar en formato fecha, ¿no?
df_main_reduced$Date<-as.Date(df_main_reduced$Date)
#comprobar que los cambios se han guardado en el dataframe
str(df_main_reduced)
#Tipos del conjunto df_store: HACERLO VOSOTROS CON ESTE DF
str(df_store)
df_store<-df_store_excel
df_store$StoreType<-as.factor(df_store$StoreType)
df_store$Assortment<-as.factor(df_store$Assortment)
df_store$Promo2<-as.factor(df_store$Promo2)
df_store$Store<-as.character(df_store$Store)
df_store$CompetitionOpenSinceYear<-as.factor(df_store$CompetitionOpenSinceYear)
df_store$Promo2SinceYear<-as.factor(df_store$Promo2SinceYear)
df_store$PromoInterval<-as.factor(df_store$PromoInterval)
#Poner años e intervalos mensuales como factor, ¿porqué hacemos esto?
df_store$CompetitionOpenSinceYear<-as.factor(df_store$CompetitionOpenSinceYear)
df_store$Promo2SinceYear<-as.factor(df_store$Promo2SinceYear)
df_store$PromoInterval<-as.factor(df_store$PromoInterval)
str(df_store)
#Conjunto main
summary(df_main_reduced)
#solo hay valores perdidos en Open y parece que muy pocos, veamos que % de los datos es
#is.na() devuelve TRUE donde hay valores vacios
#sum() suma valores, el valor TRUE lo cuenta como 1
number_of_nas_in_open<-sum(is.na(df_main_reduced$Open))
#¿cuantos son en proporción al total?
(number_of_nas_in_open/nrow(df_main_reduced))*100
#son muy pocos, podemos borrar esas filas: indicamos  quedarnos solo con las filas que NO sean na en esa varuable
df_main_reduced<-df_main_reduced[!is.na(df_main_reduced$Open),]
sum(is.na(df_main_reduced$Open))
#comprobamos que se han guardado los cambios y ya no tenemos ningún valor perdido
#(aunque si nos fijamos mejor, vemos que solo es en la tienda 622)
summary(df_main_reduced)
#Hacerlo con conjunto store
summary(df_store)
#SOLUCIÓN
df_store<-df_store[!is.na(df_store$CompetitionDistance),]
(sum(is.na(df_store$CompetitionOpenSinceMonth))/nrow(df_store))*100
#¿Es por alguna razón concreta? Veamos estas filas
df_store[is.na(df_store$CompetitionOpenSinceMonth),]
df_store[is.na(df_store$Promo2SinceWeek),]
library(data.table)
col="Promo2SinceWeek"
#Convertimos el dataframe a datatable para usar función set (:=)
df_store %>% setDT()
df_store<-data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
df_store[, Promo2SinceWeek:=as.character(Promo2SinceWeek)]
df_store<-data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
df_store$Promo2SinceWeek<-as.factor(df_store$Promo2SinceWeek)
summary(df_store)
#lo  hacemos para el resto de casos de fechas derivadas de promo2
col="Promo2SinceYear"
data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
col="PromoInterval"
data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
summary(df_store)
#¿Como podríamos comprobar si son las mismas filas que las funciones que conocemos hasta ahora?
length(unique(df_store$Store))
nrow(df_store)
sum(is.na(df_store$CompetitionOpenSinceMonth))
sum(is.na(df_store$CompetitionOpenSinceYear))
sum(df_store[is.na(CompetitionOpenSinceMonth),]$Store==df_store[is.na(CompetitionOpenSinceYear),]$Store)
#Nas coinciden para ambas columnas
#Es un porcentaje alto, podríamos, por ejemplo, imputarlo, o analizarlo más para encontrar la causa
#Por ahora vamos a eliminarlas  ya que no tienen interés analítico en este ejercicio
df_store[,CompetitionOpenSinceMonth:=NULL]
df_store[,CompetitionOpenSinceYear:=NULL]
summary(df_store)
#Conjunto store
summary(df_store)
table(df_store$Assortment)
prop.table(table(df_store$Assortment))*100
prop.table(table(df_store$StoreType))*100
df_store<-df_store[StoreType!="b",]
table(df_store$StoreType)
#El resto de valores parece normalmente distribuido
library(funModeling)
freq(df_store)
#--------------------------EJERCICIO--------------------------
#Conjunto main
summary(df_main_reduced)
freq(df_main_reduced)
#2.5. Otros
#Ordenar df por fecha
summary(df_main_reduced)
df_main_reduced %>% setDT()
df_main_reduced<-df_main_reduced[order(Date)]
setnames(df_main_reduced, old = c("SchoolHoliday", "Customers","Store"),new = c("SchoolHolidayAffected", "NumberOfCustomers", "StoreId"), skip_absent=TRUE)
str(df_main_reduced)
#SOLUCIÓN
setnames(df_store, old = c("Store"),new = c("StoreId"), skip_absent=TRUE)
str(df_store)
library(plyr)
df_main_reduced$Open <- revalue(df_main_reduced$Open, c("0"="No", "1"="Yes"))
levels(df_main_reduced$Open)
df_main_reduced$Promo <- revalue(df_main_reduced$Promo, c("0"="No", "1"="Yes"))
df_main_reduced$StateHoliday <- revalue(df_main_reduced$StateHoliday, c("a"="Public_H", "b"="Easter_H", "c"="Christmas_H", "0"="None_H"))
df_main_reduced$SchoolHolidayAffected <- revalue(df_main_reduced$SchoolHolidayAffected, c("0"="NotAffected", "1"="Affected"))
#Comprobamos que se han guardado los cambios
str(df_main_reduced)
df_store$Assortment <- revalue(df_store$Assortment, c("a"="basic", "b"="extra", "c"="extended"))
df_store$Promo2  <- revalue(df_store$StateHoliday, c("0"="NotApplied", "1"="Applied"))
str(df_store)
#Conjunto store
summary(df_store)
hist(df_store$CompetitionDistance)
df_store<-dplyr::filter(df_store, CompetitionDistance<40000) #Con dplyr
#Con utilidades de R: df_store<-df_store[df_store$CompetitionDistance<40000,]
hist(df_store$CompetitionDistance)
table(df_store$Promo2SinceYear)
#Conjunto main
summary(df_main_reduced)
hist(df_main_reduced$Sales)
hist(df_main_reduced$NumberOfCustomers)
#Indicador de competidor a menos de 10k metros
df_store %>% setDT()
df_store[,near_competitor:=ifelse(CompetitionDistance<1000, "Yes", "No")]
#Usando lo aprendido en filtros del apartado anterior, filtramos por la nueva variable creada y comprobamos la distancia maxima
df_filtrado_competidoresCercanos<-dplyr::filter(df_store, near_competitor=="Yes")
max(df_filtrado_competidoresCercanos$CompetitionDistance)
#Ventas por cliente para cada fecha y tienda
df_main_reduced[,sales_per_client:=(Sales/NumberOfCustomers)]
df_main_reduced[,sales_per_client:=ifelse(Sales==0 & NumberOfCustomers==0,0,(Sales/NumberOfCustomers))]
df_main_reduced
round(df_main_reduced$sales_per_client)
round(df_main_reduced$sales_per_client,1)
# b) Columna que indique si las ventas por cliente son mayores a la media de ventas por cliente
hist(df_main_reduced$sales_per_client)
media=mean(df_main_reduced$sales_per_client)
df_main_reduced[,bigger_than_mean:=ifelse(sales_per_client>media, "Si", "No")]
df_agregado1<-df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(sum_sales_by_holiday=sum(Sales)) %>% setDT()
# b) Media de ventas por cada tipo de vacaciones estatales
df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(mean_sales_by_holiday=mean(Sales)) %>% setDT()
# c) Media de clientes por cada tipo de vacaciones estatales
df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(mean_customers_by_holiday=mean(NumberOfCustomers)) %>% setDT()
# d) Ventas por cliente por cada tipo de grado de diversidad
df_main_reduced %>% dplyr::group_by(Assortment) %>% dplyr::summarise(salesClient_by_assortment=sum(sales_per_client)) %>% setDT()
# d) Ventas por cliente por cada tipo de grado de diversidad y vacaciones estatales
df_main_reduced %>% dplyr::group_by(Assortment, StateHoliday) %>% dplyr::summarise(salesClient_by_assortment_and_holiday=sum(sales_per_client)) %>% setDT()
#Con unión interna nos quedamos solo con las filas en las que hay coincidencia en StoreId, por lo tanto,
#tendrá, como máximo el tamaño del menor conjunto de la unión (y como mínimo 0, ya que podrían no tener id coincidentes)
df_unioin_interna<-dplyr::inner_join(df_main_reduced, df_store, by = "StoreId")
#¿Como lo haríamos ahora si cuando hemos renombrado columnas no le hubiéramos puesto el mismo nombre?
dim(df_unioin_interna)
sum(is.na(df_unioin_interna))
#Con la unión completa tendremos todos los valores distintos de todas las columnas
df_unioin_completa<-dplyr::full_join(df_main_reduced, df_store, by = "StoreId")
dim(df_unioin_completa)
sum(is.na(df_unioin_completa))
#--------------------------EJERCICIO------------------------------------------------------
#Ejercicio: ¿Y si quisieramos quedarnos solo con los valores conjunto de los id del conjunto main? (Mirar cheatsheet para resolver)
df_unioin_completa<-dplyr::right_join(df_main_reduced, df_store, by = "StoreId")
#Cjto main
str(df_main_reduced)
#Guardamos un df auxiliar con las variables numéricas (todas las filas y columnas con los nombres indicados)
df_main_numericas<-df_main_reduced[,names(df_main_reduced) %in% c("Sales", "NumberOfCustomers", "sales_per_client"), with=FALSE]
#Diagramas de cajas y bigotes
boxplot(df_main_numericas)
par(mfrow=c(1,2))
boxplot(df_main_reduced$NumberOfCustomers)
hist(df_main_reduced$NumberOfCustomers)
par(mfrow=c(1,2))
boxplot(df_main_reduced$sales_per_client)
hist(df_main_reduced$NumberOfCustomers)
df_main_reduced[,NumberOfCustomers_log:=log(NumberOfCustomers)]
par(mfrow=c(1,2))
boxplot(df_main_reduced$NumberOfCustomers_log)
hist(df_main_reduced$NumberOfCustomers_log)
df_main_reduced[,NumberOfCustomers:=ifelse(NumberOfCustomers<0,0,NumberOfCustomers)]
boxplot(df_main_reduced$NumberOfCustomers)
hist(df_main_reduced$NumberOfCustomers)
df_main_reduced[,sales_per_client_log:=log(sales_per_client)]
par(mfrow=c(1,2))
boxplot(df_main_reduced$sales_per_client_log, main="Boxplotlog Ventas/Cliente")
hist(df_main_reduced$sales_per_client_log, main="Histograma log Ventas/Cliente", xlab="ventas por cliente")
str(main_store)
#¿Como afectan los tramos de promociones a las ventas?
#Están en conjuntos distintos, pero ya hemos visto antes que podemos unirlos
main_store <- merge(df_main_reduced, df_store, by = "StoreId")
#Definir directorio de trabajo
getwd()
setwd("/Users/nairachiclana/Documents/Github/R_for_BI-Season2/") #Cambiar por el personal de cada uno
#Comprobar que se ha configurado correctamente
getwd()
# -----------Leer archivo csv con read.table() ---------------------------------------------
df_main_table<-read.table("data/Rossmann/main.csv") # sep= " " por defecto
df_main_table<-read.table("data/Rossmann/main.csv", sep=",") #header=FALSE por defecto
head(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv", header=TRUE, sep=",")
head(df_main_table)
#Otras utilidades de la función read.table()
?read.table()
#leer solo las n primeras lineas
dim(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv", header=TRUE, sep=",", nrows=1000)
dim(df_main_table)
#empezar a leer 1000 lineas después de las 300 primeras lineas
head(df_main_table)
df_main_table<-read.table("data/Rossmann/main.csv",  sep=",", nrows=1000, skip=300)
head(df_main_table)
#crear vector de nombres
name_of_columns=c("Id", "Store", "DayOfWeek", "Date", "Open", "Promo", "StateHoliday", "SchoolHoliday")
df_main_table<-read.table("data/Rossmann/main.csv",  sep=",", nrows=1000, skip=300, col.names=name_of_columns)
head(df_main_table)
# -----------Leer archivo csv con read.csv()---------------------------------------------
df_main_csv<-read.csv("data/Rossmann/main.csv") #header=TRUE and sep="," por defecto
head(df_main_csv)
?read.csv
#install.packages("readxl")
library(readxl)
library(xlsx)
df_store_excel<-read_excel("data/Rossmann/store.xlsm")
head(df_store_excel)
class(df_store_excel)
df_store_excel2<-read.xlsx(xlsxFile="data/Rossmann/store.xlsm")
head(df_store_excel2)
?read.xlsx
#Leemos hoja distinta a la princial
read.xlsx("data/Rossmann/store.xlsm", sheet=2) #por defecto salta lineas vacías al principio del archivo
#SOLUCIÓN
read.xlsx("data/Rossmann/store.xlsm", sheet=2, colNames=FALSE, na.strings=c("-", " "))
read.xlsx("data/Rossmann/store.xlsm", sheet=2, colNames=TRUE, check.names=TRUE)
#Con la función dim() podemos definir o ver la dimensión de un objeto. En un df vemos el número de filas y columnas.
dim(df_main_csv)
dim(df_store_excel)
#El conjunto "main" es algo grande, lo reduciremos a 500k observaciones para tratarlo con más velocidad.
#Nos quedaremos con 50k filas de forma aleatoria para intentar que los datos se sesguen lo mínimo posible.
#La función sample_n selecciona aleatoriamente las  filas indicadas del conjunto
library(dplyr)
df_main_reduced<-sample_n(df_main_csv, 500000)
dim(df_main_reduced)
#Para elegir el número de filas de forma dinámica, sabiendo que queremos más o menos la mitad,
#podemos crear una variable con el valor de la mitad del número de filas, obtenido con la función nrow()
mitad_filas<-nrow(df_main_csv)/2
df_main_reduced<-sample_n(df_main_csv, mitad_filas)
dim(df_main_reduced)
#Tipos de datos del conjunto df_main
str(df_main_reduced)
#con la función unique() vemos los valores distintos que contiene una variable
unique(df_main_reduced$DayOfWeek)
#día de la semana tiene solo 7 valores distintos, por lo que la convertiremos de numérica a factor con la función as.factor()
df_main_reduced$DayOfWeek<-as.factor(df_main_reduced$DayOfWeek)
#comprobamos que se ha transformado correctamente con la función class()
class(df_main_reduced$DayOfWeek)
#Realizamos el mismo proceso para la variable Promo
unique(df_main_reduced$Promo)
df_main_reduced$Promo<-as.factor(df_main_reduced$Promo)
class(df_main_reduced$Promo)
#Y para la variable SchoolHoliday
unique(df_main_reduced$SchoolHoliday)
df_main_reduced$SchoolHoliday<-as.factor(df_main_reduced$SchoolHoliday)
class(df_main_reduced$SchoolHoliday)
#La fecha, debería estar en formato fecha, ¿no?
df_main_reduced$Date<-as.Date(df_main_reduced$Date)
#comprobar que los cambios se han guardado en el dataframe
str(df_main_reduced)
#Tipos del conjunto df_store: HACERLO VOSOTROS CON ESTE DF
str(df_store)
df_store<-df_store_excel
df_store$StoreType<-as.factor(df_store$StoreType)
df_store$Assortment<-as.factor(df_store$Assortment)
df_store$Promo2<-as.factor(df_store$Promo2)
df_store$Store<-as.character(df_store$Store)
df_store$CompetitionOpenSinceYear<-as.factor(df_store$CompetitionOpenSinceYear)
df_store$Promo2SinceYear<-as.factor(df_store$Promo2SinceYear)
df_store$PromoInterval<-as.factor(df_store$PromoInterval)
#Poner años e intervalos mensuales como factor, ¿porqué hacemos esto?
df_store$CompetitionOpenSinceYear<-as.factor(df_store$CompetitionOpenSinceYear)
df_store$Promo2SinceYear<-as.factor(df_store$Promo2SinceYear)
df_store$PromoInterval<-as.factor(df_store$PromoInterval)
str(df_store)
#Conjunto main
summary(df_main_reduced)
#solo hay valores perdidos en Open y parece que muy pocos, veamos que % de los datos es
#is.na() devuelve TRUE donde hay valores vacios
#sum() suma valores, el valor TRUE lo cuenta como 1
number_of_nas_in_open<-sum(is.na(df_main_reduced$Open))
#¿cuantos son en proporción al total?
(number_of_nas_in_open/nrow(df_main_reduced))*100
#son muy pocos, podemos borrar esas filas: indicamos  quedarnos solo con las filas que NO sean na en esa varuable
df_main_reduced<-df_main_reduced[!is.na(df_main_reduced$Open),]
sum(is.na(df_main_reduced$Open))
#comprobamos que se han guardado los cambios y ya no tenemos ningún valor perdido
#(aunque si nos fijamos mejor, vemos que solo es en la tienda 622)
summary(df_main_reduced)
#Hacerlo con conjunto store
summary(df_store)
#SOLUCIÓN
df_store<-df_store[!is.na(df_store$CompetitionDistance),]
(sum(is.na(df_store$CompetitionOpenSinceMonth))/nrow(df_store))*100
#¿Es por alguna razón concreta? Veamos estas filas
df_store[is.na(df_store$CompetitionOpenSinceMonth),]
df_store[is.na(df_store$Promo2SinceWeek),]
library(data.table)
col="Promo2SinceWeek"
#Convertimos el dataframe a datatable para usar función set (:=)
df_store %>% setDT()
df_store<-data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
df_store[, Promo2SinceWeek:=as.character(Promo2SinceWeek)]
df_store<-data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
df_store$Promo2SinceWeek<-as.factor(df_store$Promo2SinceWeek)
summary(df_store)
#lo  hacemos para el resto de casos de fechas derivadas de promo2
col="Promo2SinceYear"
data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
col="PromoInterval"
data.table::set(df_store, i=which(is.na(df_store[[col]])), j=col, value="NoPromo2")
summary(df_store)
#¿Como podríamos comprobar si son las mismas filas que las funciones que conocemos hasta ahora?
length(unique(df_store$Store))
nrow(df_store)
sum(is.na(df_store$CompetitionOpenSinceMonth))
sum(is.na(df_store$CompetitionOpenSinceYear))
sum(df_store[is.na(CompetitionOpenSinceMonth),]$Store==df_store[is.na(CompetitionOpenSinceYear),]$Store)
#Nas coinciden para ambas columnas
#Es un porcentaje alto, podríamos, por ejemplo, imputarlo, o analizarlo más para encontrar la causa
#Por ahora vamos a eliminarlas  ya que no tienen interés analítico en este ejercicio
df_store[,CompetitionOpenSinceMonth:=NULL]
df_store[,CompetitionOpenSinceYear:=NULL]
summary(df_store)
#Conjunto store
summary(df_store)
table(df_store$Assortment)
prop.table(table(df_store$Assortment))*100
prop.table(table(df_store$StoreType))*100
df_store<-df_store[StoreType!="b",]
table(df_store$StoreType)
#El resto de valores parece normalmente distribuido
library(funModeling)
freq(df_store)
#--------------------------EJERCICIO--------------------------
#Conjunto main
summary(df_main_reduced)
freq(df_main_reduced)
#2.5. Otros
#Ordenar df por fecha
summary(df_main_reduced)
df_main_reduced %>% setDT()
df_main_reduced<-df_main_reduced[order(Date)]
setnames(df_main_reduced, old = c("SchoolHoliday", "Customers","Store"),new = c("SchoolHolidayAffected", "NumberOfCustomers", "StoreId"), skip_absent=TRUE)
str(df_main_reduced)
#SOLUCIÓN
setnames(df_store, old = c("Store"),new = c("StoreId"), skip_absent=TRUE)
str(df_store)
library(plyr)
df_main_reduced$Open <- revalue(df_main_reduced$Open, c("0"="No", "1"="Yes"))
levels(df_main_reduced$Open)
df_main_reduced$Promo <- revalue(df_main_reduced$Promo, c("0"="No", "1"="Yes"))
df_main_reduced$StateHoliday <- revalue(df_main_reduced$StateHoliday, c("a"="Public_H", "b"="Easter_H", "c"="Christmas_H", "0"="None_H"))
df_main_reduced$SchoolHolidayAffected <- revalue(df_main_reduced$SchoolHolidayAffected, c("0"="NotAffected", "1"="Affected"))
#Comprobamos que se han guardado los cambios
str(df_main_reduced)
df_store$Assortment <- revalue(df_store$Assortment, c("a"="basic", "b"="extra", "c"="extended"))
df_store$Promo2  <- revalue(df_store$StateHoliday, c("0"="NotApplied", "1"="Applied"))
str(df_store)
#Conjunto store
summary(df_store)
hist(df_store$CompetitionDistance)
df_store<-dplyr::filter(df_store, CompetitionDistance<40000) #Con dplyr
#Con utilidades de R: df_store<-df_store[df_store$CompetitionDistance<40000,]
hist(df_store$CompetitionDistance)
table(df_store$Promo2SinceYear)
#Conjunto main
summary(df_main_reduced)
hist(df_main_reduced$Sales)
hist(df_main_reduced$NumberOfCustomers)
#Indicador de competidor a menos de 10k metros
df_store %>% setDT()
df_store[,near_competitor:=ifelse(CompetitionDistance<1000, "Yes", "No")]
#Usando lo aprendido en filtros del apartado anterior, filtramos por la nueva variable creada y comprobamos la distancia maxima
df_filtrado_competidoresCercanos<-dplyr::filter(df_store, near_competitor=="Yes")
max(df_filtrado_competidoresCercanos$CompetitionDistance)
#Ventas por cliente para cada fecha y tienda
df_main_reduced[,sales_per_client:=(Sales/NumberOfCustomers)]
df_main_reduced[,sales_per_client:=ifelse(Sales==0 & NumberOfCustomers==0,0,(Sales/NumberOfCustomers))]
df_main_reduced
round(df_main_reduced$sales_per_client)
round(df_main_reduced$sales_per_client,1)
# b) Columna que indique si las ventas por cliente son mayores a la media de ventas por cliente
hist(df_main_reduced$sales_per_client)
media=mean(df_main_reduced$sales_per_client)
df_main_reduced[,bigger_than_mean:=ifelse(sales_per_client>media, "Si", "No")]
df_agregado1<-df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(sum_sales_by_holiday=sum(Sales)) %>% setDT()
# b) Media de ventas por cada tipo de vacaciones estatales
df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(mean_sales_by_holiday=mean(Sales)) %>% setDT()
# c) Media de clientes por cada tipo de vacaciones estatales
df_main_reduced %>% dplyr::group_by(StateHoliday) %>% dplyr::summarise(mean_customers_by_holiday=mean(NumberOfCustomers)) %>% setDT()
# d) Ventas por cliente por cada tipo de grado de diversidad
df_main_reduced %>% dplyr::group_by(Assortment) %>% dplyr::summarise(salesClient_by_assortment=sum(sales_per_client)) %>% setDT()
# d) Ventas por cliente por cada tipo de grado de diversidad y vacaciones estatales
df_main_reduced %>% dplyr::group_by(Assortment, StateHoliday) %>% dplyr::summarise(salesClient_by_assortment_and_holiday=sum(sales_per_client)) %>% setDT()
#Con unión interna nos quedamos solo con las filas en las que hay coincidencia en StoreId, por lo tanto,
#tendrá, como máximo el tamaño del menor conjunto de la unión (y como mínimo 0, ya que podrían no tener id coincidentes)
df_unioin_interna<-dplyr::inner_join(df_main_reduced, df_store, by = "StoreId")
#¿Como lo haríamos ahora si cuando hemos renombrado columnas no le hubiéramos puesto el mismo nombre?
dim(df_unioin_interna)
sum(is.na(df_unioin_interna))
#Con la unión completa tendremos todos los valores distintos de todas las columnas
df_unioin_completa<-dplyr::full_join(df_main_reduced, df_store, by = "StoreId")
dim(df_unioin_completa)
sum(is.na(df_unioin_completa))
#--------------------------EJERCICIO------------------------------------------------------
#Ejercicio: ¿Y si quisieramos quedarnos solo con los valores conjunto de los id del conjunto main? (Mirar cheatsheet para resolver)
df_unioin_completa<-dplyr::right_join(df_main_reduced, df_store, by = "StoreId")
str(df_main_reduced)
str(df_store)
